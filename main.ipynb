{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in vs code terminal, create conda environment with python: conda create --name *myenv* python=3.9\n",
    "#pip install numpy==1.26.4 opencv-python==4.7.0.72 mediapipe==0.10.21\n",
    "#make sure kernel is opt/anaconda3/envs/try/bin/python\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test cell, ensure camera permissions are on\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "cap = cv.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    " \n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    # Display the resulting frame\n",
    "    cv.imshow('frame', gray)\n",
    "    if cv.waitKey(1) == ord('q'): #press q when on camera capture window only\n",
    "        break\n",
    " \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762309798.300369  262013 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1762309798.317744  262120 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1762309798.328529  262120 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1762309798.351226  262119 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/KaylaNguyen/Desktop/try/images\n",
      "Goldendoodle: {'face ratio': 1.04, 'eye distance': 422.9, 'nose ratio': 0.16, 'eye color': [48, 56, 67], 'skin color': [101, 136, 182]}\n",
      "German Shepherd: {'face ratio': 1.14, 'eye distance': 132.0, 'nose ratio': 0.2, 'eye color': [81, 78, 79], 'skin color': [49, 68, 97]}\n",
      "Siberian Husky: {'face ratio': 1.13, 'eye distance': 299.0, 'nose ratio': 0.21, 'eye color': [175, 139, 86], 'skin color': [148, 149, 148]}\n",
      "French Bulldog: {'face ratio': 1.0, 'eye distance': 1178.1, 'nose ratio': 0.15, 'eye color': [14, 10, 13], 'skin color': [79, 100, 119]}\n",
      "Chihuahua: {'face ratio': 1.02, 'eye distance': 243.2, 'nose ratio': 0.24, 'eye color': [71, 67, 75], 'skin color': [130, 150, 179]}\n",
      "Shiba: {'face ratio': 1.13, 'eye distance': 195.0, 'nose ratio': 0.28, 'eye color': [31, 38, 50], 'skin color': [136, 168, 205]}\n",
      "Maltipoo: {'face ratio': 1.03, 'eye distance': 176.1, 'nose ratio': 0.28, 'eye color': [26, 24, 24], 'skin color': [153, 163, 171]}\n",
      "Golden Retreiver: {'face ratio': 1.11, 'eye distance': 160.6, 'nose ratio': 0.23, 'eye color': [29, 23, 20], 'skin color': [95, 127, 161]}\n",
      "Dachshund: {'face ratio': 1.13, 'eye distance': 168.0, 'nose ratio': 0.09, 'eye color': [42, 42, 45], 'skin color': [65, 100, 147]}\n",
      "Chocolate Lab: {'face ratio': 1.17, 'eye distance': 225.1, 'nose ratio': 0.22, 'eye color': [76, 86, 86], 'skin color': [74, 94, 119]}\n"
     ]
    }
   ],
   "source": [
    "#analyze dog breeds through static images to create a dictionary of dog breed features\n",
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#initialize mediapipe face mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=True,   #turn on still images\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5\n",
    ")\n",
    "\n",
    "#define image folder in correct directiry\n",
    "current_directory = os.getcwd()\n",
    "images_path = os.path.join(current_directory, \"images\")\n",
    "#check that program is accessing the correct images folder\n",
    "print(images_path)\n",
    "image_files = [f for f in os.listdir(images_path) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "#dictionary for dog breeds and their facial features\n",
    "dogs = {}\n",
    "\n",
    "for img_file in image_files:\n",
    "    img_path = os.path.join(images_path, img_file)\n",
    "    image = cv.imread(img_path)\n",
    "    if image is None:\n",
    "        print(f\"Could not read image {img_file}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    h, w, _ = image.shape\n",
    "    rgb_image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    result = face_mesh.process(rgb_image)\n",
    "\n",
    "    if result.multi_face_landmarks:\n",
    "        for face_landmarks in result.multi_face_landmarks:\n",
    "            #convert landmark coordinates to pixel positions\n",
    "            points = np.array([(int(lm.x * w), int(lm.y * h)) for lm in face_landmarks.landmark])\n",
    "\n",
    "            #face size (height/width)\n",
    "            x_min, y_min = np.min(points, axis=0)\n",
    "            x_max, y_max = np.max(points, axis=0)\n",
    "            face_width = x_max - x_min\n",
    "            face_height = y_max - y_min\n",
    "            face_ratio = face_height / face_width if face_width != 0 else 0\n",
    "\n",
    "            #eye distance\n",
    "            left_eye_idx = 33\n",
    "            right_eye_idx = 263\n",
    "            eye_dist = np.linalg.norm(np.array(points[left_eye_idx]) - np.array(points[right_eye_idx]))\n",
    "\n",
    "            #nose ratio\n",
    "            nose_tip_idx = 1\n",
    "            nose_bottom_idx = 2\n",
    "            nose_left_idx = 98\n",
    "            nose_right_idx = 327\n",
    "            nose_length = np.linalg.norm(np.array(points[nose_tip_idx]) - np.array(points[nose_bottom_idx]))\n",
    "            nose_width = np.linalg.norm(np.array(points[nose_left_idx]) - np.array(points[nose_right_idx]))\n",
    "            nose_ratio = nose_length / nose_width if nose_width != 0 else 0\n",
    "\n",
    "            #eye color\n",
    "            l_eye_center = points[468]\n",
    "            r_eye_center = points[473]\n",
    "            patch_size = 3\n",
    "            l_patch = image[l_eye_center[1]-patch_size:l_eye_center[1]+patch_size,\n",
    "                            l_eye_center[0]-patch_size:l_eye_center[0]+patch_size]\n",
    "            r_patch = image[r_eye_center[1]-patch_size:r_eye_center[1]+patch_size,\n",
    "                            r_eye_center[0]-patch_size:r_eye_center[0]+patch_size]\n",
    "            eye_color = None\n",
    "            if l_patch.size > 0 and r_patch.size > 0:\n",
    "                eye_color = np.mean(np.vstack((l_patch.reshape(-1, 3), r_patch.reshape(-1, 3))), axis=0).astype(int)\n",
    "\n",
    "            #skin color\n",
    "            face_roi = image[y_min:y_max, x_min:x_max]\n",
    "            skin_color = None\n",
    "            if face_roi.size > 0:\n",
    "                skin_color = np.mean(face_roi.reshape(-1, 3), axis=0).astype(int)\n",
    "            \n",
    "            #store results in dogs dictionary\n",
    "            breed = os.path.splitext(img_file)[0]\n",
    "            breed = breed.replace(\"_\", \" \")\n",
    "            dogs[breed] = {\n",
    "                \"face ratio\": round(face_ratio, 2),\n",
    "                \"eye distance\": round(eye_dist, 1),\n",
    "                \"nose ratio\": round(nose_ratio, 2),\n",
    "                \"eye color\": eye_color.tolist() if eye_color is not None else None,\n",
    "                \"skin color\": skin_color.tolist() if skin_color is not None else None\n",
    "            }\n",
    "\n",
    "    else:\n",
    "        print(f\"No face detected in {img_file}\")\n",
    "        dogs[img_file] = None\n",
    "\n",
    "for k, v in dogs.items():\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762309804.254397  262013 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M2\n",
      "W0000 00:00:1762309804.256580  262204 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1762309804.266501  262202 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face ratio: 1.20\n",
      "Eye distance: 279.9px\n",
      "Nose ratio: 0.20\n",
      "Eye color: Black (BGR: [14 12 28])\n",
      "Skin color: Peru (BGR: [ 94 116 170])\n",
      "--------------------------------------------------\n",
      "Closestdog breed: Chihuahua (distance = 111.20)\n",
      "Face ratio: 1.20\n",
      "Eye distance: 279.9px\n",
      "Nose ratio: 0.20\n",
      "Eye color: Black (BGR: [16 12 27])\n",
      "Skin color: Peru (BGR: [104 119 176])\n",
      "--------------------------------------------------\n",
      "Closestdog breed: Chihuahua (distance = 106.52)\n",
      "Face ratio: 1.20\n",
      "Eye distance: 278.8px\n",
      "Nose ratio: 0.21\n",
      "Eye color: Black (BGR: [22 19 39])\n",
      "Skin color: Peru (BGR: [104 119 176])\n",
      "--------------------------------------------------\n",
      "Closestdog breed: Chihuahua (distance = 94.41)\n",
      "Face ratio: 1.20\n",
      "Eye distance: 280.8px\n",
      "Nose ratio: 0.20\n",
      "Eye color: Black (BGR: [15 12 28])\n",
      "Skin color: Peru (BGR: [104 119 176])\n",
      "--------------------------------------------------\n",
      "Closestdog breed: Chihuahua (distance = 106.92)\n"
     ]
    }
   ],
   "source": [
    "#main code \n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    " \n",
    "CSS3_COLORS = {\n",
    "    \"AntiqueWhite\": \"#FAEBD7\",\n",
    "    \"AliceBlue\": \"#F0F8FF\",\n",
    "    \"Aqua\": \"#00FFFF\",\n",
    "    \"Aquamarine\": \"#7FFFD4\",\n",
    "    \"Azure\": \"#F0FFFF\",\n",
    "    \"Beige\": \"#F5F5DC\",\n",
    "    \"Bisque\": \"#FFE4C4\",\n",
    "    \"Black\": \"#000000\",\n",
    "    \"BlanchedAlmond\": \"#FFEBCD\",\n",
    "    \"Brown\": \"#A52A2A\",\n",
    "    \"BurlyWood\": \"#DEB887\",\n",
    "    \"CadetBlue\": \"#5F9EA0\",\n",
    "    \"Chocolate\": \"#D2691E\",\n",
    "    \"Coral\": \"#FF7F50\",\n",
    "    \"CornflowerBlue\": \"#6495ED\",\n",
    "    \"Cornsilk\": \"#FFF8DC\",\n",
    "    \"DarkGoldenRod\": \"#B8860B\",\n",
    "    \"DarkGray\": \"#A9A9A9\",\n",
    "    \"DarkGreen\": \"#006400\",\n",
    "    \"DarkKhaki\": \"#BDB76B\",\n",
    "    \"DarkOliveGreen\": \"#556B2F\",\n",
    "    \"DarkSlateGray\": \"#2F4F4F\",\n",
    "    \"DeepSkyBlue\": \"#00BFFF\",\n",
    "    \"GhostWhite\": \"#F8F8FF\",\n",
    "    \"GoldenRod\": \"#DAA520\",\n",
    "    \"LemonChiffon\": \"#FFFACD\",\n",
    "    \"LightBlue\": \"#ADD8E6\",\n",
    "    \"LightGoldenRodYellow\": \"#FAFAD2\",\n",
    "    \"LightSkyBlue\": \"#87CEFA\",\n",
    "    \"LightSteelBlue\": \"#B0C4DE\",\n",
    "    \"Moccasin\": \"#FFE4B5\",\n",
    "    \"NavajoWhite\": \"#FFDEAD\",\n",
    "    \"Orange\": \"#FFA500\",\n",
    "    \"Peru\": \"#CD853F\",\n",
    "    \"SaddleBrown\": \"#8B4513\",\n",
    "    \"SandyBrown\": \"#F4A460\",\n",
    "    \"Tan\": \"#D2B48C\",\n",
    "    \"Aqua\": \"#00FFFF\"\n",
    "}\n",
    "\n",
    "def color_distance(c1, c2):\n",
    "    if c1 is None or c2 is None:\n",
    "        return 0\n",
    "    return np.linalg.norm(np.array(c1) - np.array(c2))\n",
    "\n",
    "def feature_distance(human, dog):\n",
    "    dist = 0\n",
    "    dist += (human[\"face_ratio\"] - dog[\"face ratio\"])**2\n",
    "    dist += (human[\"eye distance\"] - dog[\"eye distance\"])**2\n",
    "    dist += (human[\"nose ratio\"] - dog[\"nose ratio\"])**2\n",
    "    dist += color_distance(human[\"eye color\"], dog[\"eye color\"])**2\n",
    "    dist += color_distance(human[\"skin color\"], dog[\"skin color\"])**2\n",
    "    return np.sqrt(dist)\n",
    "\n",
    "def find_closest_breed(human, dogs):\n",
    "    best_breed = None\n",
    "    min_dist = float('inf')\n",
    "    for breed, features in dogs.items():\n",
    "        if features is None:\n",
    "            continue\n",
    "        dist = feature_distance(human, features)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            best_breed = breed\n",
    "    return best_breed, min_dist\n",
    "\n",
    "#convert hex string to rgb tuple\n",
    "def hex_to_rgb(hex_str):\n",
    "    hex_str = hex_str.lstrip(\"#\")\n",
    "    return tuple(int(hex_str[i:i+2], 16) for i in (0, 2, 4))\n",
    "\n",
    "#helper function to get color names\n",
    "def color_name(bgr):\n",
    "    rgb = bgr[::-1]\n",
    "    min_dist = float('inf')\n",
    "    closest_name = \"Unknown\"\n",
    "    for name, hex_val in CSS3_COLORS.items():\n",
    "        r_val, g_val, b_val = hex_to_rgb(hex_val)\n",
    "        dist = (r_val - rgb[0])**2 + (g_val - rgb[1])**2 + (b_val - rgb[2])**2\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            closest_name = name\n",
    "    return closest_name\n",
    "\n",
    "\n",
    "#initialize mediapipe face mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=False,\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "#lists to store face measurements\n",
    "face_ratios = []\n",
    "eye_dists = []\n",
    "nose_ratios = []\n",
    "eye_colors = []\n",
    "skin_colors = []\n",
    "\n",
    "#number of frames to average for output\n",
    "N = 30\n",
    "\n",
    "#previous facial detection values for comparison\n",
    "prev_face_ratio = None\n",
    "prev_eye_dist = None\n",
    "prev_nose_ratio = None\n",
    "prev_eye_color = None\n",
    "prev_skin_color = None\n",
    "\n",
    "#thresholds for facial difference\n",
    "FACE_RATIO_THRESH = 0.05\n",
    "EYE_DIST_THRESH = 10 #pixel\n",
    "NOSE_RATIO_THRESH = 0.05\n",
    "COLOR_THRESH = 3.0  #euclidean dist in bgr space\n",
    "\n",
    "#if color change is over threshold then return\n",
    "def color_change(c1, c2):\n",
    "    if c1 is None or c2 is None:\n",
    "        return True\n",
    "    return np.linalg.norm(c1 - c2) > COLOR_THRESH\n",
    "\n",
    "#start video capture\n",
    "cap = cv.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    " \n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    \n",
    "    #convert to RGB for mediapipe processing\n",
    "    rgb_frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "    result = face_mesh.process(rgb_frame)\n",
    "\n",
    "    #convert back to BGR for opencv \n",
    "    frame = cv.cvtColor(rgb_frame, cv.COLOR_RGB2BGR)\n",
    "\n",
    "    h, w, _ = frame.shape\n",
    "\n",
    "    if result.multi_face_landmarks:\n",
    "        for face_landmarks in result.multi_face_landmarks:\n",
    "            #convert landmark coordinates to pixel positions\n",
    "            points = np.array([(int(lm.x * w), int(lm.y * h)) for lm in face_landmarks.landmark])\n",
    "\n",
    "            #face size (height/width)\n",
    "            x_min, y_min = np.min(points, axis=0)\n",
    "            x_max, y_max = np.max(points, axis=0)\n",
    "            face_width = x_max - x_min\n",
    "            face_height = y_max - y_min\n",
    "            face_ratio = face_height / face_width if face_width != 0 else 0\n",
    "\n",
    "            #eye distance\n",
    "            left_eye_idx = 33\n",
    "            right_eye_idx = 263\n",
    "            eye_dist = np.linalg.norm(np.array(points[left_eye_idx]) - np.array(points[right_eye_idx]))\n",
    "\n",
    "            #nose size\n",
    "            nose_tip_idx = 1\n",
    "            nose_bottom_idx = 2\n",
    "            nose_left_idx = 98\n",
    "            nose_right_idx = 327\n",
    "            nose_length = np.linalg.norm(np.array(points[nose_tip_idx]) - np.array(points[nose_bottom_idx]))\n",
    "            nose_width = np.linalg.norm(np.array(points[nose_left_idx]) - np.array(points[nose_right_idx]))\n",
    "            nose_ratio = nose_length / nose_width if nose_width != 0 else 0\n",
    "\n",
    "            #eye color\n",
    "            l_eye_center = points[468]\n",
    "            r_eye_center = points[473]\n",
    "            patch_size = 3\n",
    "            l_patch = frame[l_eye_center[1]-patch_size:l_eye_center[1]+patch_size,\n",
    "                            l_eye_center[0]-patch_size:l_eye_center[0]+patch_size]\n",
    "            r_patch = frame[r_eye_center[1]-patch_size:r_eye_center[1]+patch_size,\n",
    "                            r_eye_center[0]-patch_size:r_eye_center[0]+patch_size]\n",
    "            eye_color = None\n",
    "            if l_patch.size > 0 and r_patch.size > 0:\n",
    "                eye_color = np.mean(np.vstack((l_patch.reshape(-1, 3), r_patch.reshape(-1, 3))), axis=0).astype(int)\n",
    "\n",
    "            #skin color\n",
    "            face_roi = frame[y_min:y_max, x_min:x_max]\n",
    "            skin_color = None\n",
    "            if face_roi.size > 0:\n",
    "                skin_color = np.mean(face_roi.reshape(-1, 3), axis=0).astype(int)\n",
    "\n",
    "            #append calculations to lists for averaging\n",
    "            face_ratios.append(face_ratio)\n",
    "            eye_dists.append(eye_dist)\n",
    "            nose_ratios.append(nose_ratio)\n",
    "            if eye_color is not None:\n",
    "                eye_colors.append(eye_color)\n",
    "            if skin_color is not None:\n",
    "                skin_colors.append(skin_color)\n",
    "\n",
    "            #compute averages\n",
    "            if len(face_ratios) >= N:\n",
    "                avg_face_ratio = sum(face_ratios[-N:]) / N\n",
    "                avg_eye_distance = sum(eye_dists[-N:]) / N\n",
    "                avg_nose_ratio = sum(nose_ratios[-N:]) / N\n",
    "                avg_eye_color = np.mean(np.array(eye_colors[-N:]), axis=0).astype(int)\n",
    "                avg_skin_color = np.mean(np.array(skin_colors[-N:]), axis=0).astype(int)\n",
    "                \n",
    "                #calculate if change in facial detection is over threshold\n",
    "                change = (\n",
    "                    prev_face_ratio is None or \n",
    "                    abs(avg_face_ratio - prev_face_ratio) > FACE_RATIO_THRESH or\n",
    "                    abs(avg_eye_distance - prev_eye_dist) > EYE_DIST_THRESH or\n",
    "                    abs(avg_nose_ratio - prev_nose_ratio) > NOSE_RATIO_THRESH or\n",
    "                    color_change(avg_eye_color, prev_eye_color) or\n",
    "                    color_change(avg_skin_color, prev_skin_color)\n",
    "                )\n",
    "\n",
    "                #if change is over threshold, change color names and output\n",
    "                if change:\n",
    "                    eye_color_name = color_name(avg_eye_color)\n",
    "                    skin_color_name = color_name(avg_skin_color)\n",
    "\n",
    "                    #print output\n",
    "                    human = {\n",
    "                        \"face_ratio\": avg_face_ratio,\n",
    "                        \"eye distance\": avg_eye_distance,\n",
    "                        \"nose ratio\": avg_nose_ratio,\n",
    "                        \"eye color\": avg_eye_color,\n",
    "                        \"skin color\": avg_skin_color,\n",
    "                    }\n",
    "                    print(\"Face ratio: {:.2f}\".format(avg_face_ratio))\n",
    "                    print(\"Eye distance: {:.1f}px\".format(avg_eye_distance))\n",
    "                    print(\"Nose ratio: {:.2f}\".format(avg_nose_ratio))\n",
    "                    print(\"Eye color:\", eye_color_name, \"(BGR: {})\".format(avg_eye_color))\n",
    "                    print(\"Skin color:\", skin_color_name, \"(BGR: {})\".format(avg_skin_color))\n",
    "                    print(\"-\"*50)\n",
    "\n",
    "                    closest_breed, distance = find_closest_breed(human, dogs)\n",
    "                    print(f\"Closest dog breed: {closest_breed} (distance = {distance:.2f})\")\n",
    "\n",
    "                    #update previous values\n",
    "                    prev_face_ratio = avg_face_ratio\n",
    "                    prev_eye_dist = avg_eye_distance\n",
    "                    prev_nose_ratio = avg_nose_ratio\n",
    "                    prev_eye_color = avg_eye_color\n",
    "                    prev_skin_color = avg_skin_color\n",
    "\n",
    "                # clear lists to restart averaging\n",
    "                face_ratios.clear()\n",
    "                eye_dists.clear()\n",
    "                nose_ratios.clear()\n",
    "                eye_colors.clear()\n",
    "                skin_colors.clear()\n",
    "\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv.imshow('frame', frame)\n",
    "    if cv.waitKey(1) == ord('q'): #press q when on camera capture window only\n",
    "        break\n",
    " \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
